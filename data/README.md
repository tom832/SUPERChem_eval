# Data Directory

This directory contains the data used for the evaluation of Large Language Models (LLMs). This includes baseline human performance data, metadata about the questions, and mappings for dataset splits.

---

## File Descriptions

### `20251015_baseline.csv`
This CSV file contains the baseline results generated by humans. It serves as a benchmark to compare the performance of the LLM models against. Each row corresponds to a question and includes the human-provided answer and analysis.

### `ability_tags_description.json`
This JSON file provides a comprehensive classification of all possible "ability tags" that a question might involve. These tags categorize the skills and knowledge areas being tested, such as "Logical Reasoning," "Mathematical Calculation," or "Code Understanding." This file is used to understand the scope of abilities covered in the benchmark.

### `dataset_split_map.json`
This file contains a pre-classification of the questions based on their difficulty level. It is used to split the dataset into different subsets (e.g., easy, medium, hard) for more granular analysis of model performance across varying levels of complexity.

### `internal_uuid.csv`
This CSV file contains a list of UUIDs (Universally Unique Identifiers) that correspond to internal educational questions from specific schools or institutions. This is used to map and reference a specific subset of proprietary questions within the larger dataset.